__all__ = ['SynthSplineDataset']
import nibabel as nib
import numpy as np
import torch
import os
from glob import glob
from pathlib import Path


class SynthSplineDataset(torch.utils.data.Dataset):
    """
    An iterator across a synthetic label set generated by a `LabelApp`.

    !!! warning "Returned tensors have a leading channel dimension"

    !!! note
        The dataset can return any of the volumes generated by the
        synthesis machine, either a single one or multiple ones.
        The argument `keys` controls which volume(s) is returned.

        - if keys contains a string, each iteration of the dataset
          returns a single tensor;
        - if keys contains a list (or tuple) of strings, each iteration
          of the dataset returns a list of tensors in the same order,
          _even if its length is one_.

        List of valid keys:

        - prob : soft (partial volume) probability of being in a spline
        - dist : Euclidean distance map to the nearest centerline
        - label : Label map where each spline has a unique ID
        - level : Label map that encodes the hierarchical level of each spline
        - nblevel : Label map that encodes the number of levels in each tree
        - branch : Mask of branching points
        - skeleton : Mask of the centerlines
    """

    ALL_KEYS = (
        'prob',
        'dist',
        'label',
        'level',
        'nblevel',
        'branch',
        'skeleton',
    )

    KEY_TO_DTYPE = {
        'prob': torch.float32,
        'dist': torch.float32,
        'label': torch.int32,
        'level': torch.uint8,
        'nblevel': torch.uint8,
        'branch': torch.bool,
        'skeleton': torch.bool,
    }

    def __init__(self, path, keys='label', dtype=None, subset=None):
        """
        Parameters
        ----------
        path : str
            Path to dataset folder.
        keys : [list of] {"prob", "dist", "label", "level", "nvlevel", "branch", "skeleton"}
            Which volume(s) should the dataset return.
        dtype : [dict or list of] torch.dtype
            Returned data type.
            If a single value, used for all tensor.
            Can also be a list, which should then have the same length
            as `keys`, or a dict mapping each key to a data type.
        subset : [list of] slice or int
            Encodes the subset of data to load. All by default.
        """  # noqa: E501

        if not isinstance(path, (str, Path)):
            raise TypeError('Path should be a `str` or a `Path`')
        if not os.path.isdir(path):
            raise ValueError('Path should be an existing folder')
        if isinstance(keys, (list, tuple)):
            if any(key not in self.ALL_KEYS for key in keys):
                raise ValueError('Invalid key')
        elif isinstance(keys, str):
            if keys not in self.ALL_KEYS:
                raise ValueError('Invalid key')
        else:
            raise TypeError('Keys should be a `str` or `list[str]`')
        if subset and not isinstance(subset, (list, tuple, slice)):
            raise TypeError('Subset should be a `slice` or `list[int]`')

        if isinstance(dtype, (list, tuple)):
            if not isinstance(keys, (list, tuple)):
                raise TypeError('If dtype is a list, keys should be a list')
            if len(dtype) != len(keys):
                raise ValueError('dtype and list should have the same length')
            dtype = {key: dt for key, dt in zip(keys, dtype)}
        if isinstance(dtype, dict):
            tmp = dtype
            dtype = dict(self.KEY_TO_DTYPE)
            dtype.update(tmp)
        elif isinstance(dtype, torch.dtype):
            dtype = {key: dtype for key in self.KEY_TO_DTYPE}
        elif dtype is None:
            dtype = dict(self.KEY_TO_DTYPE)
        else:
            raise TypeError('DType should be a list or dict of torch.dtype')

        self.path = path
        self.keys = keys
        self.dtype = dtype
        self.subset = subset
        self.prob = self._find_fnames('prob')
        self.dist = self._find_fnames('dist')
        self.label = self._find_fnames('label')
        self.level = self._find_fnames('level')
        self.nblevel = self._find_fnames('nblevel')
        self.branch = self._find_fnames('branch')
        self.skeleton = self._find_fnames('skeleton')

    def _find_fnames(self, key):
        return list(sorted(glob(os.path.join(self.path, f'*_{key}.nii.gz'))))

    def _subset(self, fnames):
        if isinstance(self.subset, slice):
            return fnames[self.subset]
        elif isinstance(self.subset, (list, tuple)):
            fnames, ifnames = [], fnames
            for i in self.subset:
                if isinstance(i, slice):
                    fnames += ifnames[i]
                else:
                    fnames += [ifnames[i]]
        return fnames

    def __len__(self):
        fnames = self._subset(self.prob)
        return len(fnames)

    def _load(self, fname, dtype):
        f = nib.load(fname)
        if dtype.is_floating_point:
            npdtype = str(dtype).split('.')[-1]
            dat = f.get_fdata(dtype=npdtype)
            dat = torch.as_tensor(dat, dtype=dtype)
        else:
            dat = np.asarray(f.dataobj)
            dat = torch.as_tensor(dat, dtype=dtype)
        dat = dat.squeeze()[None]
        return dat

    def __getitem__(self, index):
        if isinstance(self.keys, str):
            fname = self._subset(getattr(self, self.keys))[index]
            return self._load(fname, dtype=self.dtype[self.keys])
        else:
            return type(self.keys)(
                self._load(
                    self._subset(getattr(self, key))[index],
                    dtype=self.dtype[key]
                )
                for key in self.keys
            )
